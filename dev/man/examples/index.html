<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Examples Â· MendelIHT</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">MendelIHT</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../Introduction/">What is IHT?</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li class="is-active"><a class="tocitem" href>Examples</a><ul class="internal"><li><a class="tocitem" href="#Example-1:-How-to-Import-Data-1"><span>Example 1: How to Import Data</span></a></li><li><a class="tocitem" href="#Example-2:-Running-IHT-on-Quantitative-Traits-1"><span>Example 2: Running IHT on Quantitative Traits</span></a></li><li><a class="tocitem" href="#Example-3:-Logistic-Regression-Controlling-for-Sex-1"><span>Example 3: Logistic Regression Controlling for Sex</span></a></li><li><a class="tocitem" href="#Example-4:-Poisson-Regression-with-Acceleration-(i.e.-debias)-1"><span>Example 4: Poisson Regression with Acceleration (i.e. debias)</span></a></li><li><a class="tocitem" href="#Example-5:-Negative-Binomial-regression-with-group-information-1"><span>Example 5: Negative Binomial regression with group information</span></a></li><li><a class="tocitem" href="#Example-6:-Linear-Regression-with-prior-weights-1"><span>Example 6: Linear Regression with prior weights</span></a></li><li><a class="tocitem" href="#Other-examples-and-functionalities-1"><span>Other examples and functionalities</span></a></li></ul></li><li><a class="tocitem" href="../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Examples</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Examples</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/OpenMendel/MendelIHT.jl/blob/master/docs/src/man/examples.md" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Examples-1"><a class="docs-heading-anchor" href="#Examples-1">Examples</a><a class="docs-heading-anchor-permalink" href="#Examples-1" title="Permalink"></a></h1><p>Here we give numerous example analysis of GWAS data with MendelIHT. </p><pre><code class="language-julia"># machine information for reproducibility
versioninfo()</code></pre><pre><code class="language-none">Julia Version 1.0.3
Commit 099e826241 (2018-12-18 01:34 UTC)
Platform Info:
  OS: macOS (x86_64-apple-darwin14.5.0)
  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)</code></pre><pre><code class="language-julia">#first add workers needed for parallel computing. Add only as many CPU cores available
using Distributed
addprocs(4)

#load necessary packages for running all examples below
using MendelIHT
using SnpArrays
using DataFrames
using Distributions
using Random
using LinearAlgebra
using GLM
using DelimitedFiles
using Statistics
using BenchmarkTools</code></pre><h2 id="Example-1:-How-to-Import-Data-1"><a class="docs-heading-anchor" href="#Example-1:-How-to-Import-Data-1">Example 1: How to Import Data</a><a class="docs-heading-anchor-permalink" href="#Example-1:-How-to-Import-Data-1" title="Permalink"></a></h2><p>We use <a href="https://openmendel.github.io/SnpArrays.jl/latest/">SnpArrays.jl</a> as backend to process genotype files. Internally, the genotype file is a memory mapped <a href="https://openmendel.github.io/SnpArrays.jl/stable/#SnpArray-1">SnpArray</a>, which will not be loaded into RAM. If you wish to run <code>L0_reg</code>, you need to convert a SnpArray into a <a href="https://openmendel.github.io/SnpArrays.jl/stable/#SnpBitMatrix-1">SnpBitMatrix</a>, which consumes <span>$n \times p \times 2$</span> bits of RAM. Non-genetic predictors should be read into Julia in the standard way, and should be stored as an <code>Array{Float64, 2}</code>. One should include the intercept (typically in the first column), but an intercept is not required to run IHT. </p><h3 id="Simulate-example-data-(to-be-imported-later)-1"><a class="docs-heading-anchor" href="#Simulate-example-data-(to-be-imported-later)-1">Simulate example data (to be imported later)</a><a class="docs-heading-anchor-permalink" href="#Simulate-example-data-(to-be-imported-later)-1" title="Permalink"></a></h3><p>First we simulate an example PLINK trio (<code>.bim</code>, <code>.bed</code>, <code>.fam</code>) and non-genetic covariates, then we illustrate how to import them. For genotype matrix simulation, we simulate under the model:</p><div>\[x_{ij} \sim \rm Binomial(2, \rho_j)\]</div><div>\[\rho_j \sim \rm Uniform(0, 0.5)\]</div><pre><code class="language-julia"># rows and columns
n = 1000
p = 10000

#random seed
Random.seed!(1111)

# simulate random `.bed` file
x = simulate_random_snparray(n, p, &quot;example.bed&quot;)

# create accompanying `.bim`, `.fam` files (randomly generated)
make_bim_fam_files(x, ones(n), &quot;example&quot;)

# simulate non-genetic covariates (in this case, we include intercept and sex)
z = [ones(n, 1) rand(0:1, n)]
writedlm(&quot;example_nongenetic_covariates.txt&quot;, z)</code></pre><h3 id="Reading-Genotype-data-and-Non-Genetic-Covariates-from-disk-1"><a class="docs-heading-anchor" href="#Reading-Genotype-data-and-Non-Genetic-Covariates-from-disk-1">Reading Genotype data and Non-Genetic Covariates from disk</a><a class="docs-heading-anchor-permalink" href="#Reading-Genotype-data-and-Non-Genetic-Covariates-from-disk-1" title="Permalink"></a></h3><pre><code class="language-julia">x = SnpArray(&quot;example.bed&quot;)
z = readdlm(&quot;example_nongenetic_covariates.txt&quot;)</code></pre><pre><code class="language-none">1000Ã—2 Array{Float64,2}:
 1.0  1.0
 1.0  0.0
 1.0  0.0
 1.0  1.0
 1.0  0.0
 1.0  0.0
 1.0  1.0
 1.0  0.0
 1.0  1.0
 1.0  1.0
 1.0  0.0
 1.0  0.0
 1.0  1.0
 â‹®       
 1.0  0.0
 1.0  1.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  1.0
 1.0  0.0</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>(1) MendelIHT.jl assumes there are <strong>NO missing genotypes</strong>, (2) 1 always encode the minor allele, and (3) the trios (<code>.bim</code>, <code>.bed</code>, <code>.fam</code>) are all be present in the same directory. </p></div></div><h3 id="Standardizing-Non-Genetic-Covariates.-1"><a class="docs-heading-anchor" href="#Standardizing-Non-Genetic-Covariates.-1">Standardizing Non-Genetic Covariates.</a><a class="docs-heading-anchor-permalink" href="#Standardizing-Non-Genetic-Covariates.-1" title="Permalink"></a></h3><p>We recommend standardizing all genetic and non-genetic covarariates (including binary and categorical), except for the intercept. This ensures equal penalization for all predictors. For genotype matrix, <code>SnpBitMatrix</code> efficiently achieves this standardization. For non-genetic covariates, we use the built-in function <code>standardize!</code>. </p><pre><code class="language-julia"># SnpBitMatrix can automatically standardizes .bed file (without extra memory) and behaves like a matrix
xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);

# using view is important for correctness
standardize!(@view(z[:, 2:end])) 
z</code></pre><pre><code class="language-none">1000Ã—2 Array{Float64,2}:
 1.0   1.0015  
 1.0  -0.997503
 1.0  -0.997503
 1.0   1.0015  
 1.0  -0.997503
 1.0  -0.997503
 1.0   1.0015  
 1.0  -0.997503
 1.0   1.0015  
 1.0   1.0015  
 1.0  -0.997503
 1.0  -0.997503
 1.0   1.0015  
 â‹®             
 1.0  -0.997503
 1.0   1.0015  
 1.0  -0.997503
 1.0  -0.997503
 1.0  -0.997503
 1.0  -0.997503
 1.0  -0.997503
 1.0  -0.997503
 1.0  -0.997503
 1.0  -0.997503
 1.0   1.0015  
 1.0  -0.997503</code></pre><pre><code class="language-julia"># remove simulated data once they are no longer needed
rm(&quot;example.bed&quot;, force=true)
rm(&quot;example.bim&quot;, force=true)
rm(&quot;example.fam&quot;, force=true)
rm(&quot;example_nongenetic_covariates.txt&quot;, force=true)</code></pre><h2 id="Example-2:-Running-IHT-on-Quantitative-Traits-1"><a class="docs-heading-anchor" href="#Example-2:-Running-IHT-on-Quantitative-Traits-1">Example 2: Running IHT on Quantitative Traits</a><a class="docs-heading-anchor-permalink" href="#Example-2:-Running-IHT-on-Quantitative-Traits-1" title="Permalink"></a></h2><p>Quantitative traits are continuous phenotypes whose distribution can be modeled by the normal distribution. Then using the genotype matrix <span>$\mathbf{X}$</span> and phenotype vector <span>$\mathbf{y}$</span>, we want to recover <span>$\beta$</span> such that <span>$\mathbf{y} \approx \mathbf{X}\beta$</span>. In this example, we assume we know the true sparsity level <code>k</code>. </p><h3 id="Step-1:-Import-data-1"><a class="docs-heading-anchor" href="#Step-1:-Import-data-1">Step 1: Import data</a><a class="docs-heading-anchor-permalink" href="#Step-1:-Import-data-1" title="Permalink"></a></h3><p>In Example 1 we illustrated how to import data into Julia. So here we use simulated data (<a href="https://github.com/biona001/MendelIHT.jl/blob/master/src/simulate_utilities.jl#L107">code</a>) because, only then, can we compare IHT&#39;s result to the true solution. Below we simulate a GWAS data with <span>$n=1000$</span> patients and <span>$p=10000$</span> SNPs. Here the quantitative trait vector are affected by <span>$k = 10$</span> causal SNPs, with no non-genetic confounders. </p><p>In this example, our model is simulated as:</p><div>\[y_i \sim \mathbf{x}_i^T\mathbf{\beta} + \epsilon_i\]</div><div>\[x_{ij} \sim \rm Binomial(2, \rho_j)\]</div><div>\[\rho_j \sim \rm Uniform(0, 0.5)\]</div><div>\[\epsilon_i \sim \rm N(0, 1)\]</div><div>\[\beta_i \sim \rm N(0, 1)\]</div><pre><code class="language-julia"># Define model dimensions, true model size, distribution, and link functions
n = 1000
p = 10000
k = 10
d = Normal
l = canonicallink(d())

# set random seed for reproducibility
Random.seed!(2019) 

# simulate SNP matrix, store the result in a file called tmp.bed
x = simulate_random_snparray(n, p, &quot;tmp.bed&quot;)

#construct the SnpBitMatrix type (needed for L0_reg() and simulate_random_response() below)
xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true); 

# intercept is the only nongenetic covariate
z = ones(n, 1) 

# simulate response y, true model b, and the correct non-0 positions of b
y, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);</code></pre><h3 id="Step-2:-Run-cross-validation-to-determine-best-model-size-1"><a class="docs-heading-anchor" href="#Step-2:-Run-cross-validation-to-determine-best-model-size-1">Step 2: Run cross validation to determine best model size</a><a class="docs-heading-anchor-permalink" href="#Step-2:-Run-cross-validation-to-determine-best-model-size-1" title="Permalink"></a></h3><p>To run <code>cv_iht</code>, you must specify <code>path</code> and <code>num_fold</code>, defined below:</p><ul><li><code>path</code> are all the model sizes you wish to test, stored in a vector of integers.</li><li><code>num_fold</code> indicates how many disjoint partitions of the samples is requested. </li></ul><p>By default, we partition the training/testing data randomly, but you can change this by inputing the <code>fold</code> vector as optional argument. In this example we tested <span>$k = 1, 2, ..., 20$</span> across 3 fold cross validation. This is equivalent to running IHT across 60 different models, and hence, is ideal for parallel computing (which you specify by <code>parallel=true</code>). </p><pre><code class="language-julia">path = collect(1:20)
num_folds = 3
mses = cv_iht(d(), l, x, z, y, 1, path, num_folds, parallel=true); #here 1 is for number of groups</code></pre><pre><code class="language-none">Crossvalidation Results:
	k	MSE
	1	1927.0765190526674
	2	1443.8788742220863
	3	1080.041135323195
	4	862.2385953735204
	5	705.1014346627649
	6	507.3949359364219
	7	391.96868764622843
	8	368.45440222003174
	9	350.642794092518
	10	345.8380848576577
	11	350.5188147284578
	12	359.42391568519577
	13	363.70956969599075
	14	377.30732985896975
	15	381.0310879522694
	16	392.56439238382615
	17	396.81166049333797
	18	397.3010019298764
	19	406.47023764639624
	20	410.4672260807978</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><strong>DO NOT remove</strong> intermediate files with random filenames as generated by <code>cv_iht()</code>. These are necessary auxiliary files that will be automatically removed when cross validation completes. </p></div></div><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>Because Julia employs a JIT compiler, the first round of any function call run will always take longer and consume extra memory. Therefore it is advised to always run a small &quot;test example&quot; (such as this one!) before running cross validation on a large dataset. </p></div></div><h3 id="Step-3:-Run-full-model-on-the-best-estimated-model-size-1"><a class="docs-heading-anchor" href="#Step-3:-Run-full-model-on-the-best-estimated-model-size-1">Step 3: Run full model on the best estimated model size</a><a class="docs-heading-anchor-permalink" href="#Step-3:-Run-full-model-on-the-best-estimated-model-size-1" title="Permalink"></a></h3><p><code>cv_iht</code> finished in less than a minute. </p><p>According to our cross validation result, the best model size that minimizes deviance residuals (i.e. MSE on the q-th subset of samples) is attained at <span>$k = 10$</span>. That is, cross validation detected that we need 10 SNPs to achieve the best model size. Using this information, one can re-run the IHT algorithm on the <em>full</em> dataset to obtain the best estimated model.</p><pre><code class="language-julia">k_est = argmin(mses)
result = L0_reg(x, xbm, z, y, 1, k_est, d(), l) </code></pre><pre><code class="language-none">IHT estimated 10 nonzero SNP predictors and 0 non-genetic predictors.

Compute time (sec):     0.4135408401489258
Final loglikelihood:    -1406.8807653835697
Iterations:             6

Selected genetic predictors:
10Ã—2 DataFrame
â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚
â”‚     â”‚ [90mInt64[39m    â”‚ [90mFloat64[39m     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 853      â”‚ -1.24117    â”‚
â”‚ 2   â”‚ 877      â”‚ -0.234676   â”‚
â”‚ 3   â”‚ 924      â”‚ 0.82014     â”‚
â”‚ 4   â”‚ 2703     â”‚ 0.583403    â”‚
â”‚ 5   â”‚ 4241     â”‚ 0.298304    â”‚
â”‚ 6   â”‚ 4783     â”‚ -1.14459    â”‚
â”‚ 7   â”‚ 5094     â”‚ 0.673012    â”‚
â”‚ 8   â”‚ 5284     â”‚ -0.709736   â”‚
â”‚ 9   â”‚ 7760     â”‚ 0.16866     â”‚
â”‚ 10  â”‚ 8255     â”‚ 1.08117     â”‚

Selected nongenetic predictors:
0Ã—2 DataFrame</code></pre><h3 id="Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-1"><a class="docs-heading-anchor" href="#Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-1">Step 4 (only for simulated data): Check final model against simulation</a><a class="docs-heading-anchor-permalink" href="#Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-1" title="Permalink"></a></h3><p>Since all our data and model was simulated, we can see how well <code>cv_iht</code> combined with <code>L0_reg</code> estimated the true model. For this example, we find that IHT found every simulated predictor, with 0 false positives. </p><pre><code class="language-julia">compare_model = DataFrame(
    true_Î²      = true_b[correct_position], 
    estimated_Î² = result.beta[correct_position])
@show compare_model

#clean up. Windows user must do this step manually (outside notebook/REPL)
rm(&quot;tmp.bed&quot;, force=true)</code></pre><pre><code class="language-none">compare_model = 10Ã—2 DataFrame
â”‚ Row â”‚ true_Î²   â”‚ estimated_Î² â”‚
â”‚     â”‚ Float64  â”‚ Float64     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ -1.29964 â”‚ -1.24117    â”‚
â”‚ 2   â”‚ -0.2177  â”‚ -0.234676   â”‚
â”‚ 3   â”‚ 0.786217 â”‚ 0.82014     â”‚
â”‚ 4   â”‚ 0.599233 â”‚ 0.583403    â”‚
â”‚ 5   â”‚ 0.283711 â”‚ 0.298304    â”‚
â”‚ 6   â”‚ -1.12537 â”‚ -1.14459    â”‚
â”‚ 7   â”‚ 0.693374 â”‚ 0.673012    â”‚
â”‚ 8   â”‚ -0.67709 â”‚ -0.709736   â”‚
â”‚ 9   â”‚ 0.14727  â”‚ 0.16866     â”‚
â”‚ 10  â”‚ 1.03477  â”‚ 1.08117     â”‚</code></pre><h2 id="Example-3:-Logistic-Regression-Controlling-for-Sex-1"><a class="docs-heading-anchor" href="#Example-3:-Logistic-Regression-Controlling-for-Sex-1">Example 3: Logistic Regression Controlling for Sex</a><a class="docs-heading-anchor-permalink" href="#Example-3:-Logistic-Regression-Controlling-for-Sex-1" title="Permalink"></a></h2><p>We show how to use IHT to handle case-control studies, while handling non-genetic covariates. In this example, we fit a logistic regression model with IHT using simulated case-control data, while controling for sex as a nongenetic covariate. </p><h3 id="Step-1:-Import-Data-1"><a class="docs-heading-anchor" href="#Step-1:-Import-Data-1">Step 1: Import Data</a><a class="docs-heading-anchor-permalink" href="#Step-1:-Import-Data-1" title="Permalink"></a></h3><p>Again we use a simulated model:</p><div>\[y_i \sim \rm Bernoulli(\mathbf{x}_i^T\mathbf{\beta})\]</div><div>\[x_{ij} \sim \rm Binomial(2, \rho_j)\]</div><div>\[\rho_j \sim \rm Uniform(0, 0.5)\]</div><div>\[\beta_i \sim \rm N(0, 1)\]</div><div>\[\beta_{\rm intercept} = 1\]</div><div>\[\beta_{\rm sex} = 1.5\]</div><p>We assumed there are <span>$k=8$</span> genetic predictors and 2 non-genetic predictors (intercept and sex) that affects the trait. The simulation code in our package does not yet handle simulations with non-genetic predictors, so we must simulate these phenotypes manually. </p><pre><code class="language-julia"># Define model dimensions, true model size, distribution, and link functions
n = 1000
p = 10000
k = 10
d = Bernoulli
l = canonicallink(d())

# set random seed for reproducibility
Random.seed!(2019)

# construct SnpArray and SnpBitMatrix
x = simulate_random_snparray(n, p, &quot;tmp.bed&quot;)
xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);

# nongenetic covariate: first column is the intercept, second column is sex: 0 = male 1 = female
z = ones(n, 2) 
z[:, 2] .= rand(0:1, n)

# randomly set genetic predictors
true_b = zeros(p) 
true_b[1:k-2] = randn(k-2)
shuffle!(true_b)

# find correct position of genetic predictors
correct_position = findall(!iszero, true_b)

# define effect size of non-genetic predictors: intercept &amp; sex
true_c = [1.0; 1.5] 

# simulate phenotype using genetic and nongenetic predictors
prob = GLM.linkinv.(l, xbm * true_b .+ z * true_c)
y = [rand(d(i)) for i in prob]
y = Float64.(y); # y must be floating point numbers</code></pre><h3 id="Step-2:-Run-cross-validation-to-determine-best-model-size-2"><a class="docs-heading-anchor" href="#Step-2:-Run-cross-validation-to-determine-best-model-size-2">Step 2: Run cross validation to determine best model size</a><a class="docs-heading-anchor-permalink" href="#Step-2:-Run-cross-validation-to-determine-best-model-size-2" title="Permalink"></a></h3><p>To run <code>cv_iht</code>, you must specify <code>path</code> and <code>num_fold</code>, defined below:</p><ul><li><code>path</code> are all the model sizes you wish to test, stored in a vector of integers.</li><li><code>num_fold</code> indicates how many disjoint partitions of the samples is requested. </li></ul><p>By default, we partition the training/testing data randomly, but you can change this by inputing the <code>fold</code> vector as optional argument. In this example we tested <span>$k = 1, 2, ..., 20$</span> across 3 fold cross validation. This is equivalent to running IHT across 60 different models, and hence, is ideal for parallel computing (which you specify by <code>parallel=true</code>). </p><pre><code class="language-julia">path = collect(1:20)
num_folds = 3
mses = cv_iht(d(), l, x, z, y, 1, path, num_folds, parallel=true); #here 1 is for number of groups</code></pre><pre><code class="language-none">Crossvalidation Results:
	k	MSE
	1	391.44426892225727
	2	365.7520496496987
	3	332.3801926093215
	4	273.2081512206048
	5	253.31631985207758
	6	234.93701288953315
	7	221.997334181244
	8	199.01688783420346
	9	208.31087723164197
	10	216.00575628120708
	11	227.91834469184545
	12	242.42456871743065
	13	261.46346209331466
	14	263.5229307137862
	15	283.30379378951073
	16	328.2771991160804
	17	290.4512419547228
	18	350.3516280657363
	19	361.61016297810295
	20	418.2370935226805</code></pre><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>In our experience, using the <code>ProbitLink</code> for logistic regressions deliver better results than <code>LogitLink</code> (which is the canonical link). But of course, one should choose the link that gives the higher loglikelihood. </p></div></div><h3 id="Step-3:-Run-full-model-on-the-best-estimated-model-size-2"><a class="docs-heading-anchor" href="#Step-3:-Run-full-model-on-the-best-estimated-model-size-2">Step 3: Run full model on the best estimated model size</a><a class="docs-heading-anchor-permalink" href="#Step-3:-Run-full-model-on-the-best-estimated-model-size-2" title="Permalink"></a></h3><p><code>cv_iht</code> finished in about a minute. </p><p>Cross validation have declared that <span>$k_{best} = 8$</span>. Using this information, one can re-run the IHT algorithm on the <em>full</em> dataset to obtain the best estimated model.</p><pre><code class="language-julia">k_est = argmin(mses)
result = L0_reg(x, xbm, z, y, 1, k_est, d(), l)</code></pre><pre><code class="language-none">IHT estimated 6 nonzero SNP predictors and 2 non-genetic predictors.

Compute time (sec):     1.6644580364227295
Final loglikelihood:    -290.4509381564733
Iterations:             37

Selected genetic predictors:
6Ã—2 DataFrame
â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚
â”‚     â”‚ [90mInt64[39m    â”‚ [90mFloat64[39m     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 1152     â”‚ 0.966731    â”‚
â”‚ 2   â”‚ 1576     â”‚ 1.56183     â”‚
â”‚ 3   â”‚ 3411     â”‚ 0.87674     â”‚
â”‚ 4   â”‚ 5765     â”‚ -1.75611    â”‚
â”‚ 5   â”‚ 5992     â”‚ -2.04506    â”‚
â”‚ 6   â”‚ 8781     â”‚ 0.760213    â”‚

Selected nongenetic predictors:
2Ã—2 DataFrame
â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚
â”‚     â”‚ [90mInt64[39m    â”‚ [90mFloat64[39m     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 1        â”‚ 0.709909    â”‚
â”‚ 2   â”‚ 2        â”‚ 1.65049     â”‚</code></pre><h3 id="Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-2"><a class="docs-heading-anchor" href="#Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-2">Step 4 (only for simulated data): Check final model against simulation</a><a class="docs-heading-anchor-permalink" href="#Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-2" title="Permalink"></a></h3><p>Since all our data and model was simulated, we can see how well <code>cv_iht</code> combined with <code>L0_reg</code> estimated the true model. For this example, we find that IHT found both nongenetic predictor, but missed 2 genetic predictors. The 2 genetic predictors that we missed had much smaller effect size, so given that we only had 1000 samples, this is hardly surprising. </p><pre><code class="language-julia">compare_model_genetics = DataFrame(
    true_Î²      = true_b[correct_position], 
    estimated_Î² = result.beta[correct_position])

compare_model_nongenetics = DataFrame(
    true_c      = true_c[1:2], 
    estimated_c = result.c[1:2])

@show compare_model_genetics
@show compare_model_nongenetics

#clean up. Windows user must do this step manually (outside notebook/REPL)
rm(&quot;tmp.bed&quot;, force=true)</code></pre><pre><code class="language-none">compare_model_genetics = 8Ã—2 DataFrame
â”‚ Row â”‚ true_Î²   â”‚ estimated_Î² â”‚
â”‚     â”‚ Float64  â”‚ Float64     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 0.961937 â”‚ 0.966731    â”‚
â”‚ 2   â”‚ 0.189267 â”‚ 0.0         â”‚
â”‚ 3   â”‚ 1.74008  â”‚ 1.56183     â”‚
â”‚ 4   â”‚ 0.879004 â”‚ 0.87674     â”‚
â”‚ 5   â”‚ 0.213066 â”‚ 0.0         â”‚
â”‚ 6   â”‚ -1.74663 â”‚ -1.75611    â”‚
â”‚ 7   â”‚ -1.93402 â”‚ -2.04506    â”‚
â”‚ 8   â”‚ 0.632786 â”‚ 0.760213    â”‚
compare_model_nongenetics = 2Ã—2 DataFrame
â”‚ Row â”‚ true_c  â”‚ estimated_c â”‚
â”‚     â”‚ Float64 â”‚ Float64     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 1.0     â”‚ 0.709909    â”‚
â”‚ 2   â”‚ 1.5     â”‚ 1.65049     â”‚</code></pre><h2 id="Example-4:-Poisson-Regression-with-Acceleration-(i.e.-debias)-1"><a class="docs-heading-anchor" href="#Example-4:-Poisson-Regression-with-Acceleration-(i.e.-debias)-1">Example 4: Poisson Regression with Acceleration (i.e. debias)</a><a class="docs-heading-anchor-permalink" href="#Example-4:-Poisson-Regression-with-Acceleration-(i.e.-debias)-1" title="Permalink"></a></h2><p>In this example, we show how debiasing can potentially achieve dramatic speedup. Our model is:</p><div>\[y_i \sim \rm Poisson(\mathbf{x}_i^T \mathbf{\beta})\]</div><div>\[x_{ij} \sim \rm Binomial(2, \rho_j)\]</div><div>\[\rho_j \sim \rm Uniform(0, 0.5)\]</div><div>\[\beta_i \sim \rm N(0, 0.3)\]</div><pre><code class="language-julia"># Define model dimensions, true model size, distribution, and link functions
n = 1000
p = 10000
k = 10
d = Poisson
l = canonicallink(d())

# set random seed for reproducibility
Random.seed!(2019)

# construct SnpArray, SnpBitMatrix, and intercept
x = simulate_random_snparray(n, p, &quot;tmp.bed&quot;)
xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);
z = ones(n, 1) 

# simulate response, true model b, and the correct non-0 positions of b
y, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);</code></pre><h3 id="First-Compare-Reconstruction-Result-1"><a class="docs-heading-anchor" href="#First-Compare-Reconstruction-Result-1">First Compare Reconstruction Result</a><a class="docs-heading-anchor-permalink" href="#First-Compare-Reconstruction-Result-1" title="Permalink"></a></h3><p>First we show that, with or without debiasing, we obtain comparable results with <code>L0_reg</code>.</p><pre><code class="language-julia">no_debias  = L0_reg(x, xbm, z, y, 1, k, d(), l, debias=false)
yes_debias = L0_reg(x, xbm, z, y, 1, k, d(), l, debias=true);</code></pre><pre><code class="language-julia">compare_model = DataFrame(
    position    = correct_position,
    true_Î²      = true_b[correct_position], 
    no_debias_Î² = no_debias.beta[correct_position],
    yes_debias_Î² = yes_debias.beta[correct_position])
@show compare_model;</code></pre><pre><code class="language-none">compare_model = 10Ã—4 DataFrame
â”‚ Row â”‚ position â”‚ true_Î²     â”‚ no_debias_Î² â”‚ yes_debias_Î² â”‚
â”‚     â”‚ Int64    â”‚ Float64    â”‚ Float64     â”‚ Float64      â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 853      â”‚ -0.389892  â”‚ -0.384161   â”‚ -0.38744     â”‚
â”‚ 2   â”‚ 877      â”‚ -0.0653099 â”‚ 0.0         â”‚ 0.0          â”‚
â”‚ 3   â”‚ 924      â”‚ 0.235865   â”‚ 0.246213    â”‚ 0.240514     â”‚
â”‚ 4   â”‚ 2703     â”‚ 0.17977    â”‚ 0.237651    â”‚ 0.225127     â”‚
â”‚ 5   â”‚ 4241     â”‚ 0.0851134  â”‚ 0.0         â”‚ 0.0894244    â”‚
â”‚ 6   â”‚ 4783     â”‚ -0.33761   â”‚ -0.300663   â”‚ -0.307515    â”‚
â”‚ 7   â”‚ 5094     â”‚ 0.208012   â”‚ 0.223384    â”‚ 0.215149     â”‚
â”‚ 8   â”‚ 5284     â”‚ -0.203127  â”‚ -0.225593   â”‚ -0.209308    â”‚
â”‚ 9   â”‚ 7760     â”‚ 0.0441809  â”‚ 0.0         â”‚ 0.0          â”‚
â”‚ 10  â”‚ 8255     â”‚ 0.310431   â”‚ 0.287363    â”‚ 0.301717     â”‚</code></pre><h3 id="Compare-Speed-and-Memory-Usage-1"><a class="docs-heading-anchor" href="#Compare-Speed-and-Memory-Usage-1">Compare Speed and Memory Usage</a><a class="docs-heading-anchor-permalink" href="#Compare-Speed-and-Memory-Usage-1" title="Permalink"></a></h3><p>Now we illustrate that debiasing may dramatically reduce computational time (in this case ~50%), at a cost of increasing the memory usage. In practice, this extra memory usage hardly matters because the matrix size will dominate for larger problems. See <a href="https://www.biorxiv.org/content/10.1101/697755v2">our paper for complete benchmark figure.</a></p><pre><code class="language-julia">@benchmark L0_reg(x, xbm, z, y, 1, k, d(), l, debias=false) seconds=15</code></pre><pre><code class="language-none">BenchmarkTools.Trial: 
  memory estimate:  2.16 MiB
  allocs estimate:  738
  --------------
  minimum time:     673.188 ms (0.00% GC)
  median time:      706.368 ms (0.00% GC)
  mean time:        708.080 ms (0.04% GC)
  maximum time:     741.125 ms (0.00% GC)
  --------------
  samples:          22
  evals/sample:     1</code></pre><pre><code class="language-julia">@benchmark L0_reg(x, xbm, z, y, 1, k, d(), l, debias=true) seconds=15</code></pre><pre><code class="language-none">BenchmarkTools.Trial: 
  memory estimate:  2.62 MiB
  allocs estimate:  1135
  --------------
  minimum time:     337.368 ms (0.00% GC)
  median time:      350.194 ms (0.00% GC)
  mean time:        349.958 ms (0.10% GC)
  maximum time:     358.095 ms (0.00% GC)
  --------------
  samples:          43
  evals/sample:     1</code></pre><pre><code class="language-julia">#clean up. Windows user must do this step manually (outside notebook/REPL)
rm(&quot;tmp.bed&quot;, force=true)</code></pre><h2 id="Example-5:-Negative-Binomial-regression-with-group-information-1"><a class="docs-heading-anchor" href="#Example-5:-Negative-Binomial-regression-with-group-information-1">Example 5: Negative Binomial regression with group information</a><a class="docs-heading-anchor-permalink" href="#Example-5:-Negative-Binomial-regression-with-group-information-1" title="Permalink"></a></h2><p>In this example, we show how to include group information to perform doubly sparse projections. Here the final model would contain at most <span>$J = 5$</span> groups where each group contains limited number of (prespecified) SNPs. For simplicity, we assume the sparsity parameter <span>$k$</span> is known. </p><h3 id="Data-simulation-1"><a class="docs-heading-anchor" href="#Data-simulation-1">Data simulation</a><a class="docs-heading-anchor-permalink" href="#Data-simulation-1" title="Permalink"></a></h3><p>To illustrate the effect of group information and prior weights, we generated correlated genotype matrix according to the procedure outlined in <a href="https://www.biorxiv.org/content/biorxiv/early/2019/11/19/697755.full.pdf">our paper</a>. In this example, each SNP belongs to 1 of 500 disjoint groups containing 20 SNPs each; <span>$j = 5$</span> distinct groups are each assigned <span>$1,2,...,5$</span> causal SNPs with effect sizes randomly chosen from <span>$\{âˆ’0.2,0.2\}$</span>. In all there 15 causal SNPs.  For grouped-IHT, we assume perfect group information. That is, the selected groups containing 1âˆ¼5 causative SNPs are assigned maximum within-group sparsity <span>$\lambda_g = 1,2,...,5$</span>. The remaining groups are assigned <span>$\lambda_g = 1$</span> (i.e. only 1 active predictor are allowed).</p><pre><code class="language-julia"># define problem size
d = NegativeBinomial
l = LogLink()
n = 1000
p = 10000
block_size = 20                  #simulation parameter
num_blocks = Int(p / block_size) #simulation parameter

# set seed
Random.seed!(2019)

# assign group membership
membership = collect(1:num_blocks)
g = zeros(Int64, p + 1)
for i in 1:length(membership)
    for j in 1:block_size
        cur_row = block_size * (i - 1) + j
        g[block_size*(i - 1) + j] = membership[i]
    end
end
g[end] = membership[end]

#simulate correlated snparray
x = simulate_correlated_snparray(n, p, &quot;tmp.bed&quot;)
z = ones(n, 1) # the intercept
x_float = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, center=true, scale=true)

#simulate true model, where 5 groups each with 1~5 snps contribute
true_b = zeros(p)
true_groups = randperm(num_blocks)[1:5]
sort!(true_groups)
within_group = [randperm(block_size)[1:1], randperm(block_size)[1:2], 
                randperm(block_size)[1:3], randperm(block_size)[1:4], 
                randperm(block_size)[1:5]]
correct_position = zeros(Int64, 15)
for i in 1:5
    cur_group = block_size * (true_groups[i] - 1)
    cur_group_snps = cur_group .+ within_group[i]
    start, last = Int(i*(i-1)/2 + 1), Int(i*(i+1)/2)
    correct_position[start:last] .= cur_group_snps
end
for i in 1:15
    true_b[correct_position[i]] = rand(-1:2:1) * 0.2
end
sort!(correct_position)

# simulate phenotype
r = 10 #nuisance parameter
Î¼ = GLM.linkinv.(l, x_float * true_b)
clamp!(Î¼, -20, 20)
prob = 1 ./ (1 .+ Î¼ ./ r)
y = [rand(d(r, i)) for i in prob] #number of failures before r success occurs
y = Float64.(y);</code></pre><pre><code class="language-julia">#run IHT without groups
k = 15
ungrouped = L0_reg(x_float, z, y, 1, k, d(), l, verbose=false)</code></pre><pre><code class="language-none">IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.

Compute time (sec):     0.11840415000915527
Final loglikelihood:    -1441.522293255591
Iterations:             27

Selected genetic predictors:
15Ã—2 DataFrame
â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚
â”‚     â”‚ [90mInt64[39m    â”‚ [90mFloat64[39m     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 3464     â”‚ -0.234958   â”‚
â”‚ 2   â”‚ 4383     â”‚ -0.135693   â”‚
â”‚ 3   â”‚ 4927     â”‚ 0.158171    â”‚
â”‚ 4   â”‚ 4938     â”‚ -0.222613   â”‚
â”‚ 5   â”‚ 5001     â”‚ -0.193739   â”‚
â”‚ 6   â”‚ 5011     â”‚ -0.162718   â”‚
â”‚ 7   â”‚ 5018     â”‚ -0.190532   â”‚
â”‚ 8   â”‚ 5090     â”‚ 0.226509    â”‚
â”‚ 9   â”‚ 5092     â”‚ -0.17756    â”‚
â”‚ 10  â”‚ 5100     â”‚ -0.140337   â”‚
â”‚ 11  â”‚ 7004     â”‚ 0.151748    â”‚
â”‚ 12  â”‚ 7011     â”‚ 0.206449    â”‚
â”‚ 13  â”‚ 7015     â”‚ -0.284706   â”‚
â”‚ 14  â”‚ 7016     â”‚ 0.218126    â”‚
â”‚ 15  â”‚ 9902     â”‚ 0.119059    â”‚

Selected nongenetic predictors:
0Ã—2 DataFrame</code></pre><pre><code class="language-julia">#run doubly sparse (group) IHT by specifying maximum number of SNPs for each group (in order)
J = 5
max_group_snps = ones(Int, num_blocks)
max_group_snps[true_groups] .= collect(1:5)
variable_group = L0_reg(x_float, z, y, J, max_group_snps, d(), l, verbose=false, group=g)</code></pre><pre><code class="language-none">IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.

Compute time (sec):     0.30719614028930664
Final loglikelihood:    -1446.3808810786898
Iterations:             16

Selected genetic predictors:
15Ã—2 DataFrame
â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚
â”‚     â”‚ [90mInt64[39m    â”‚ [90mFloat64[39m     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 3464     â”‚ -0.245853   â”‚
â”‚ 2   â”‚ 4927     â”‚ 0.160904    â”‚
â”‚ 3   â”‚ 4938     â”‚ -0.213439   â”‚
â”‚ 4   â”‚ 5001     â”‚ -0.19624    â”‚
â”‚ 5   â”‚ 5011     â”‚ -0.149913   â”‚
â”‚ 6   â”‚ 5018     â”‚ -0.181966   â”‚
â”‚ 7   â”‚ 5086     â”‚ -0.0560478  â”‚
â”‚ 8   â”‚ 5090     â”‚ 0.21164     â”‚
â”‚ 9   â”‚ 5092     â”‚ -0.141968   â”‚
â”‚ 10  â”‚ 5100     â”‚ -0.157655   â”‚
â”‚ 11  â”‚ 7004     â”‚ 0.190224    â”‚
â”‚ 12  â”‚ 7011     â”‚ 0.21294     â”‚
â”‚ 13  â”‚ 7015     â”‚ -0.256058   â”‚
â”‚ 14  â”‚ 7016     â”‚ 0.19746     â”‚
â”‚ 15  â”‚ 7020     â”‚ 0.111755    â”‚

Selected nongenetic predictors:
0Ã—2 DataFrame</code></pre><h3 id="Group-IHT-found-1-more-SNPs-than-ungrouped-IHT-1"><a class="docs-heading-anchor" href="#Group-IHT-found-1-more-SNPs-than-ungrouped-IHT-1">Group IHT found 1 more SNPs than ungrouped IHT</a><a class="docs-heading-anchor-permalink" href="#Group-IHT-found-1-more-SNPs-than-ungrouped-IHT-1" title="Permalink"></a></h3><pre><code class="language-julia">#check result
correct_position = findall(!iszero, true_b)
compare_model = DataFrame(
    position = correct_position,
    correct_Î² = true_b[correct_position],
    ungrouped_IHT_Î² = ungrouped.beta[correct_position], 
    grouped_IHT_Î² = variable_group.beta[correct_position])
@show compare_model
println(&quot;\n&quot;)

#clean up. Windows user must do this step manually (outside notebook/REPL)
rm(&quot;tmp.bed&quot;, force=true)</code></pre><pre><code class="language-none">compare_model = 15Ã—4 DataFrame
â”‚ Row â”‚ position â”‚ correct_Î² â”‚ ungrouped_IHT_Î² â”‚ grouped_IHT_Î² â”‚
â”‚     â”‚ Int64    â”‚ Float64   â”‚ Float64         â”‚ Float64       â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 3464     â”‚ -0.2      â”‚ -0.234958       â”‚ -0.245853     â”‚
â”‚ 2   â”‚ 4927     â”‚ 0.2       â”‚ 0.158171        â”‚ 0.160904      â”‚
â”‚ 3   â”‚ 4938     â”‚ -0.2      â”‚ -0.222613       â”‚ -0.213439     â”‚
â”‚ 4   â”‚ 5001     â”‚ -0.2      â”‚ -0.193739       â”‚ -0.19624      â”‚
â”‚ 5   â”‚ 5011     â”‚ -0.2      â”‚ -0.162718       â”‚ -0.149913     â”‚
â”‚ 6   â”‚ 5018     â”‚ -0.2      â”‚ -0.190532       â”‚ -0.181966     â”‚
â”‚ 7   â”‚ 5084     â”‚ -0.2      â”‚ 0.0             â”‚ 0.0           â”‚
â”‚ 8   â”‚ 5090     â”‚ 0.2       â”‚ 0.226509        â”‚ 0.21164       â”‚
â”‚ 9   â”‚ 5098     â”‚ -0.2      â”‚ 0.0             â”‚ 0.0           â”‚
â”‚ 10  â”‚ 5100     â”‚ -0.2      â”‚ -0.140337       â”‚ -0.157655     â”‚
â”‚ 11  â”‚ 7004     â”‚ 0.2       â”‚ 0.151748        â”‚ 0.190224      â”‚
â”‚ 12  â”‚ 7011     â”‚ 0.2       â”‚ 0.206449        â”‚ 0.21294       â”‚
â”‚ 13  â”‚ 7015     â”‚ -0.2      â”‚ -0.284706       â”‚ -0.256058     â”‚
â”‚ 14  â”‚ 7016     â”‚ 0.2       â”‚ 0.218126        â”‚ 0.19746       â”‚
â”‚ 15  â”‚ 7020     â”‚ 0.2       â”‚ 0.0             â”‚ 0.111755      â”‚</code></pre><h2 id="Example-6:-Linear-Regression-with-prior-weights-1"><a class="docs-heading-anchor" href="#Example-6:-Linear-Regression-with-prior-weights-1">Example 6: Linear Regression with prior weights</a><a class="docs-heading-anchor-permalink" href="#Example-6:-Linear-Regression-with-prior-weights-1" title="Permalink"></a></h2><p>In this example, we show how to include (predetermined) prior weights for each SNP. You can check out <a href="https://www.biorxiv.org/content/biorxiv/early/2019/11/19/697755.full.pdf">our paper</a> for references of why/how to choose these weights. In this case, we mimic our paper and randomly set <span>$10\%$</span> of all SNPs to have a weight of <span>$2.0$</span>. Other predictors have weight of <span>$1.0$</span>. All causal SNPs have weights of <span>$2.0$</span>. Under this scenario, SNPs with weight <span>$2.0$</span> is twice as likely to enter the model identified by IHT. </p><p>Our model is simulated as:</p><div>\[y_i \sim \mathbf{x}_i^T\mathbf{\beta} + \epsilon_i\]</div><div>\[x_{ij} \sim \rm Binomial(2, \rho_j)\]</div><div>\[\rho_j \sim \rm Uniform(0, 0.5)\]</div><div>\[\epsilon_i \sim \rm N(0, 1)\]</div><div>\[\beta_i \sim \rm N(0, 1)\]</div><pre><code class="language-julia">#random seed
Random.seed!(4)

d = Normal
l = canonicallink(d())
n = 1000
p = 10000
k = 10

# construct snpmatrix, covariate files, and true model b
x = simulate_random_snparray(n, p, &quot;tmp.bed&quot;)
X = convert(Matrix{Float64}, x, center=true, scale=true)
z = ones(n, 1) # the intercept
    
#define true_b 
true_b = zeros(p)
true_b[1:10] .= collect(0.1:0.1:1.0)
shuffle!(true_b)
correct_position = findall(!iszero, true_b)

#simulate phenotypes (e.g. vector y)
prob = GLM.linkinv.(l, X * true_b)
clamp!(prob, -20, 20)
y = [rand(d(i)) for i in prob]
y = Float64.(y);</code></pre><pre><code class="language-julia"># construct weight vector
w = ones(p + 1)
w[correct_position] .= 2.0
one_tenth = round(Int, p/10)
idx = rand(1:p, one_tenth)
w[idx] .= 2.0; #randomly set ~1/10 of all predictors to 2</code></pre><pre><code class="language-julia">#run IHT
unweighted = L0_reg(X, z, y, 1, k, d(), l, verbose=false)
weighted   = L0_reg(X, z, y, 1, k, d(), l, verbose=false, weight=w)

#check result
compare_model = DataFrame(
    position    = correct_position,
    correct     = true_b[correct_position],
    unweighted  = unweighted.beta[correct_position], 
    weighted    = weighted.beta[correct_position])
@show compare_model
println(&quot;\n&quot;)

#clean up. Windows user must do this step manually (outside notebook/REPL)
rm(&quot;tmp.bed&quot;, force=true)</code></pre><pre><code class="language-none">compare_model = 10Ã—4 DataFrame
â”‚ Row â”‚ position â”‚ correct â”‚ unweighted â”‚ weighted â”‚
â”‚     â”‚ Int64    â”‚ Float64 â”‚ Float64    â”‚ Float64  â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ 1254     â”‚ 0.4     â”‚ 0.452245   â”‚ 0.450405 â”‚
â”‚ 2   â”‚ 1495     â”‚ 0.3     â”‚ 0.306081   â”‚ 0.305738 â”‚
â”‚ 3   â”‚ 4856     â”‚ 0.8     â”‚ 0.853536   â”‚ 0.862223 â”‚
â”‚ 4   â”‚ 5767     â”‚ 0.1     â”‚ 0.0        â”‚ 0.117286 â”‚
â”‚ 5   â”‚ 5822     â”‚ 0.7     â”‚ 0.656213   â”‚ 0.651908 â”‚
â”‚ 6   â”‚ 5945     â”‚ 0.9     â”‚ 0.891915   â”‚ 0.894997 â”‚
â”‚ 7   â”‚ 6367     â”‚ 0.5     â”‚ 0.469718   â”‚ 0.472524 â”‚
â”‚ 8   â”‚ 6996     â”‚ 1.0     â”‚ 0.963236   â”‚ 0.973512 â”‚
â”‚ 9   â”‚ 7052     â”‚ 0.6     â”‚ 0.602162   â”‚ 0.600055 â”‚
â”‚ 10  â”‚ 7980     â”‚ 0.2     â”‚ 0.231389   â”‚ 0.234094 â”‚</code></pre><p>In this case, weighted IHT found an extra predictor than non-weighted IHT.</p><h2 id="Other-examples-and-functionalities-1"><a class="docs-heading-anchor" href="#Other-examples-and-functionalities-1">Other examples and functionalities</a><a class="docs-heading-anchor-permalink" href="#Other-examples-and-functionalities-1" title="Permalink"></a></h2><p>We explored a few more examples in our manuscript, with <a href="https://github.com/biona001/MendelIHT.jl/tree/master/figures">reproducible code</a>. We invite users to experiment with them as well. </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../getting_started/">Â« Getting Started</a><a class="docs-footer-nextpage" href="../contributing/">Contributing Â»</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 3 June 2020 22:18">Wednesday 3 June 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
